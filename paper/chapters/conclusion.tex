\chapter{Conclusion and future work}\label{chap:conclusions}

This thesis examines the impact of various graph parameters on the generalization error of different Graph Neural Network (GNN) architectures. I conducted extensive experiments on 49 graph classification datasets in TUDataset using four GNN models: Graph Convolutional Networks (GCN), Simplified Graph Convolution (SGC), Graph Attention Networks v2 (GATv2), and Message Passing Neural Networks (MPNN).

This work investigated the graph parameters including the average degree, the average clustering coefficient, the average shortest path length, the graph diameter, the graph density, the graph clustering coefficient, centrality measures and 1-WL color count. 

Overall, this study provides valuable insights into the relationship between graph parameters and the generalization performance of GNNs. These findings can inform the selection of appropriate GNN architectures for training and evaluation, when working with graphs of varying properties.

Future work can focus on expanding the range of GNN architectures and datasets to validate the findings across a broader spectrum. Given the considerable variation in the average number of nodes and edges and other quantitative properties of the datasets used in this thesis, it is considered to generate synthetic datasets with controlled properties to further investigate the impact of graph parameters on the generalization error of GNNs.